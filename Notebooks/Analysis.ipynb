{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, precision_recall_curve,f1_score, fbeta_score, roc_auc_score\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df.pickle','rb') as read_file:\n",
    "    df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>alcoholism</th>\n",
       "      <th>handicap</th>\n",
       "      <th>sms</th>\n",
       "      <th>no_show</th>\n",
       "      <th>schedule_hour</th>\n",
       "      <th>schedule_day</th>\n",
       "      <th>appointment_day</th>\n",
       "      <th>day_difference</th>\n",
       "      <th>appointment_weekday</th>\n",
       "      <th>schedule_weekday</th>\n",
       "      <th>prior_appointments</th>\n",
       "      <th>prior_noshows</th>\n",
       "      <th>total_conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  scholarship  hypertension  diabetes  alcoholism  handicap  \\\n",
       "2149     1.0   40          0.0           0.0       0.0         0.0       0.0   \n",
       "2154     1.0   25          0.0           0.0       0.0         0.0       0.0   \n",
       "2155     1.0   49          0.0           0.0       0.0         0.0       0.0   \n",
       "2158     1.0   58          0.0           0.0       0.0         0.0       0.0   \n",
       "2161     0.0   23          0.0           0.0       0.0         0.0       0.0   \n",
       "\n",
       "      sms  no_show  schedule_hour  schedule_day  appointment_day  \\\n",
       "2149  1.0      1.0             10            29               29   \n",
       "2154  1.0      1.0             16            29               29   \n",
       "2155  0.0      0.0             17            28               29   \n",
       "2158  1.0      0.0             10            29               29   \n",
       "2161  1.0      0.0             10            29               29   \n",
       "\n",
       "      day_difference  appointment_weekday  schedule_weekday  \\\n",
       "2149            31.0                  5.0               2.0   \n",
       "2154            31.0                  5.0               2.0   \n",
       "2155             1.0                  5.0               4.0   \n",
       "2158            31.0                  5.0               2.0   \n",
       "2161            31.0                  5.0               2.0   \n",
       "\n",
       "      prior_appointments  prior_noshows  total_conditions  \n",
       "2149                   0            0.0               0.0  \n",
       "2154                   0            0.0               0.0  \n",
       "2155                   0            0.0               0.0  \n",
       "2158                   0            0.0               0.0  \n",
       "2161                   0            0.0               0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_show</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">gender</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.643364</td>\n",
       "      <td>0.640336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.479011</td>\n",
       "      <td>0.479921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">age</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>37.521585</td>\n",
       "      <td>33.505642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>23.858740</td>\n",
       "      <td>21.885501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">scholarship</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.088913</td>\n",
       "      <td>0.108924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.284621</td>\n",
       "      <td>0.311556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">hypertension</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.206211</td>\n",
       "      <td>0.157423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.404588</td>\n",
       "      <td>0.364214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">diabetes</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.073565</td>\n",
       "      <td>0.060104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.261065</td>\n",
       "      <td>0.237689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">alcoholism</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.029532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.149269</td>\n",
       "      <td>0.169298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">handicap</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.014486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.136894</td>\n",
       "      <td>0.119487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">sms</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.317905</td>\n",
       "      <td>0.474110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.465667</td>\n",
       "      <td>0.499349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">schedule_hour</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>10.571506</td>\n",
       "      <td>11.104922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.189138</td>\n",
       "      <td>3.191370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">schedule_day</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>13.981478</td>\n",
       "      <td>15.241617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.439932</td>\n",
       "      <td>9.269438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">appointment_day</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>12.373491</td>\n",
       "      <td>12.554622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.219161</td>\n",
       "      <td>9.081063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">day_difference</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>9.704996</td>\n",
       "      <td>17.292997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>15.482681</td>\n",
       "      <td>17.222911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">appointment_weekday</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.830169</td>\n",
       "      <td>2.861785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.334328</td>\n",
       "      <td>1.375141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">schedule_weekday</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.832982</td>\n",
       "      <td>2.833213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.367322</td>\n",
       "      <td>1.370246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">prior_appointments</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.747504</td>\n",
       "      <td>0.878912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.777147</td>\n",
       "      <td>1.738872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">prior_noshows</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>0.260584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.237719</td>\n",
       "      <td>0.746130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">total_conditions</td>\n",
       "      <td>count</td>\n",
       "      <td>49779.000000</td>\n",
       "      <td>12495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.321682</td>\n",
       "      <td>0.261545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.624958</td>\n",
       "      <td>0.573358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "no_show                             0.0           1.0\n",
       "gender              count  49779.000000  12495.000000\n",
       "                    mean       0.643364      0.640336\n",
       "                    std        0.479011      0.479921\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        1.000000      1.000000\n",
       "                    75%        1.000000      1.000000\n",
       "                    max        1.000000      1.000000\n",
       "age                 count  49779.000000  12495.000000\n",
       "                    mean      37.521585     33.505642\n",
       "                    std       23.858740     21.885501\n",
       "                    min        0.000000      0.000000\n",
       "                    25%       17.000000     16.000000\n",
       "                    50%       38.000000     32.000000\n",
       "                    75%       57.000000     50.000000\n",
       "                    max      115.000000     97.000000\n",
       "scholarship         count  49779.000000  12495.000000\n",
       "                    mean       0.088913      0.108924\n",
       "                    std        0.284621      0.311556\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        0.000000      0.000000\n",
       "                    max        1.000000      1.000000\n",
       "hypertension        count  49779.000000  12495.000000\n",
       "                    mean       0.206211      0.157423\n",
       "                    std        0.404588      0.364214\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        0.000000      0.000000\n",
       "                    max        1.000000      1.000000\n",
       "diabetes            count  49779.000000  12495.000000\n",
       "                    mean       0.073565      0.060104\n",
       "                    std        0.261065      0.237689\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        0.000000      0.000000\n",
       "                    max        1.000000      1.000000\n",
       "alcoholism          count  49779.000000  12495.000000\n",
       "                    mean       0.022801      0.029532\n",
       "                    std        0.149269      0.169298\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        0.000000      0.000000\n",
       "                    max        1.000000      1.000000\n",
       "handicap            count  49779.000000  12495.000000\n",
       "                    mean       0.019104      0.014486\n",
       "                    std        0.136894      0.119487\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        0.000000      0.000000\n",
       "                    max        1.000000      1.000000\n",
       "sms                 count  49779.000000  12495.000000\n",
       "                    mean       0.317905      0.474110\n",
       "                    std        0.465667      0.499349\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        1.000000      1.000000\n",
       "                    max        1.000000      1.000000\n",
       "schedule_hour       count  49779.000000  12495.000000\n",
       "                    mean      10.571506     11.104922\n",
       "                    std        3.189138      3.191370\n",
       "                    min        6.000000      6.000000\n",
       "                    25%        8.000000      8.000000\n",
       "                    50%       10.000000     11.000000\n",
       "                    75%       13.000000     14.000000\n",
       "                    max       21.000000     21.000000\n",
       "schedule_day        count  49779.000000  12495.000000\n",
       "                    mean      13.981478     15.241617\n",
       "                    std        9.439932      9.269438\n",
       "                    min        1.000000      1.000000\n",
       "                    25%        6.000000      6.000000\n",
       "                    50%       12.000000     16.000000\n",
       "                    75%       20.000000     24.000000\n",
       "                    max       31.000000     31.000000\n",
       "appointment_day     count  49779.000000  12495.000000\n",
       "                    mean      12.373491     12.554622\n",
       "                    std        9.219161      9.081063\n",
       "                    min        1.000000      1.000000\n",
       "                    25%        5.000000      5.000000\n",
       "                    50%        9.000000     10.000000\n",
       "                    75%       19.000000     19.000000\n",
       "                    max       31.000000     31.000000\n",
       "day_difference      count  49779.000000  12495.000000\n",
       "                    mean       9.704996     17.292997\n",
       "                    std       15.482681     17.222911\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      4.000000\n",
       "                    50%        2.000000     13.000000\n",
       "                    75%       14.000000     26.000000\n",
       "                    max      179.000000    179.000000\n",
       "appointment_weekday count  49779.000000  12495.000000\n",
       "                    mean       2.830169      2.861785\n",
       "                    std        1.334328      1.375141\n",
       "                    min        1.000000      1.000000\n",
       "                    25%        2.000000      2.000000\n",
       "                    50%        3.000000      3.000000\n",
       "                    75%        4.000000      4.000000\n",
       "                    max        5.000000      5.000000\n",
       "schedule_weekday    count  49779.000000  12495.000000\n",
       "                    mean       2.832982      2.833213\n",
       "                    std        1.367322      1.370246\n",
       "                    min        1.000000      1.000000\n",
       "                    25%        2.000000      2.000000\n",
       "                    50%        3.000000      3.000000\n",
       "                    75%        4.000000      4.000000\n",
       "                    max        5.000000      5.000000\n",
       "prior_appointments  count  49779.000000  12495.000000\n",
       "                    mean       0.747504      0.878912\n",
       "                    std        1.777147      1.738872\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        1.000000      1.000000\n",
       "                    max       87.000000     61.000000\n",
       "prior_noshows       count  49779.000000  12495.000000\n",
       "                    mean       0.028004      0.260584\n",
       "                    std        0.237719      0.746130\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        0.000000      0.000000\n",
       "                    max       10.000000     17.000000\n",
       "total_conditions    count  49779.000000  12495.000000\n",
       "                    mean       0.321682      0.261545\n",
       "                    std        0.624958      0.573358\n",
       "                    min        0.000000      0.000000\n",
       "                    25%        0.000000      0.000000\n",
       "                    50%        0.000000      0.000000\n",
       "                    75%        0.000000      0.000000\n",
       "                    max        4.000000      4.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 4000\n",
    "df.groupby('no_show').describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.799354\n",
       "1.0    0.200646\n",
       "Name: no_show, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.no_show.value_counts(normalize=True) ##about 20% of patients won't show up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>alcoholism</th>\n",
       "      <th>handicap</th>\n",
       "      <th>sms</th>\n",
       "      <th>no_show</th>\n",
       "      <th>schedule_hour</th>\n",
       "      <th>schedule_day</th>\n",
       "      <th>appointment_day</th>\n",
       "      <th>day_difference</th>\n",
       "      <th>appointment_weekday</th>\n",
       "      <th>schedule_weekday</th>\n",
       "      <th>prior_appointments</th>\n",
       "      <th>prior_noshows</th>\n",
       "      <th>total_conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "      <td>62274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.642756</td>\n",
       "      <td>36.715804</td>\n",
       "      <td>0.092928</td>\n",
       "      <td>0.196422</td>\n",
       "      <td>0.070864</td>\n",
       "      <td>0.024151</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.349247</td>\n",
       "      <td>0.200646</td>\n",
       "      <td>10.678534</td>\n",
       "      <td>14.234319</td>\n",
       "      <td>12.409834</td>\n",
       "      <td>11.227495</td>\n",
       "      <td>2.836513</td>\n",
       "      <td>2.833028</td>\n",
       "      <td>0.773870</td>\n",
       "      <td>0.074670</td>\n",
       "      <td>0.309616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.479191</td>\n",
       "      <td>23.530982</td>\n",
       "      <td>0.290334</td>\n",
       "      <td>0.397295</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.153520</td>\n",
       "      <td>0.133595</td>\n",
       "      <td>0.476736</td>\n",
       "      <td>0.400487</td>\n",
       "      <td>3.196706</td>\n",
       "      <td>9.419426</td>\n",
       "      <td>9.191832</td>\n",
       "      <td>16.135783</td>\n",
       "      <td>1.342665</td>\n",
       "      <td>1.367898</td>\n",
       "      <td>1.770302</td>\n",
       "      <td>0.406868</td>\n",
       "      <td>0.615419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender           age   scholarship  hypertension      diabetes  \\\n",
       "count  62274.000000  62274.000000  62274.000000  62274.000000  62274.000000   \n",
       "mean       0.642756     36.715804      0.092928      0.196422      0.070864   \n",
       "std        0.479191     23.530982      0.290334      0.397295      0.256600   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000     17.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000     36.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000     56.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000    115.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         alcoholism      handicap           sms       no_show  schedule_hour  \\\n",
       "count  62274.000000  62274.000000  62274.000000  62274.000000   62274.000000   \n",
       "mean       0.024151      0.018178      0.349247      0.200646      10.678534   \n",
       "std        0.153520      0.133595      0.476736      0.400487       3.196706   \n",
       "min        0.000000      0.000000      0.000000      0.000000       6.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000       8.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      10.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      13.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      21.000000   \n",
       "\n",
       "       schedule_day  appointment_day  day_difference  appointment_weekday  \\\n",
       "count  62274.000000     62274.000000    62274.000000         62274.000000   \n",
       "mean      14.234319        12.409834       11.227495             2.836513   \n",
       "std        9.419426         9.191832       16.135783             1.342665   \n",
       "min        1.000000         1.000000        0.000000             1.000000   \n",
       "25%        6.000000         5.000000        0.000000             2.000000   \n",
       "50%       13.000000         9.000000        4.000000             3.000000   \n",
       "75%       22.000000        19.000000       17.000000             4.000000   \n",
       "max       31.000000        31.000000      179.000000             5.000000   \n",
       "\n",
       "       schedule_weekday  prior_appointments  prior_noshows  total_conditions  \n",
       "count      62274.000000        62274.000000   62274.000000      62274.000000  \n",
       "mean           2.833028            0.773870       0.074670          0.309616  \n",
       "std            1.367898            1.770302       0.406868          0.615419  \n",
       "min            1.000000            0.000000       0.000000          0.000000  \n",
       "25%            2.000000            0.000000       0.000000          0.000000  \n",
       "50%            3.000000            0.000000       0.000000          0.000000  \n",
       "75%            4.000000            1.000000       0.000000          0.000000  \n",
       "max            5.000000           87.000000      17.000000          4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://towardsdatascience.com/attribute-relevance-analysis-in-python-iv-and-woe-b5651443fc04\n",
    "### referencing this articles for WoE and IV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binning categorical data \n",
    "\n",
    "df_eda['age_bins'] = pd.qcut(df_eda['age'],10, duplicates='drop')\n",
    "df_eda['schedule_hour_bins'] = pd.qcut(df_eda['schedule_hour'],3, duplicates='drop')\n",
    "df_eda['schedule_day_bins'] = pd.qcut(df_eda['schedule_day'],4, duplicates='drop')\n",
    "df_eda['appointment_day_bins'] = pd.qcut(df_eda['appointment_day'],4, duplicates='drop')\n",
    "df_eda['day_difference_bins'] = pd.qcut(df_eda['day_difference'],5, duplicates='drop')\n",
    "df_eda['prior_appointments_bins'] = pd.qcut(df_eda['prior_appointments'], 4, duplicates = 'drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.drop(columns = ['age', 'schedule_hour', 'schedule_day', 'appointment_day', 'day_difference',\n",
    "                       'prior_appointments'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_woe_iv(dataset, feature, target):\n",
    "    lst = []\n",
    "    for i in range(dataset[feature].nunique()):\n",
    "        val = list(dataset[feature].unique())[i]\n",
    "        lst.append({\n",
    "            'Value': val,\n",
    "            'All': dataset[dataset[feature] == val].count()[feature],\n",
    "            'Show': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n",
    "            'No_show': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n",
    "        })\n",
    "        \n",
    "    dset = pd.DataFrame(lst)\n",
    "    dset['Distr_show'] = dset['Show'] / dset['Show'].sum()\n",
    "    dset['Distr_no_show'] = dset['No_show'] / dset['No_show'].sum()\n",
    "    dset['WoE'] = np.log(dset['Distr_show'] / dset['Distr_no_show'])\n",
    "    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "    dset['IV'] = (dset['Distr_show'] - dset['Distr_no_show']) * dset['WoE']\n",
    "    iv = dset['IV'].sum()\n",
    "    \n",
    "    dset = dset.sort_values(by='WoE')\n",
    "    \n",
    "    return dset, iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WoE and IV for column: gender\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "1    0.0  22247  17753     4494    0.356636       0.359664 -0.008453  0.000026\n",
      "0    1.0  40027  32026     8001    0.643364       0.640336  0.004717  0.000014\n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: scholarship\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "1    1.0   5787   4426     1361    0.088913       0.108924 -0.202988  0.004062\n",
      "0    0.0  56487  45353    11134    0.911087       0.891076  0.022208  0.000444\n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: hypertension\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "0    0.0  50042  39514    10528    0.793789       0.842577 -0.059648  0.002910\n",
      "1    1.0  12232  10265     1967    0.206211       0.157423  0.269966  0.013171\n",
      "IV score: 0.02\n",
      "\n",
      "\n",
      "WoE and IV for column: diabetes\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "0    0.0  57861  46117    11744    0.926435       0.939896 -0.014425  0.000194\n",
      "1    1.0   4413   3662      751    0.073565       0.060104  0.202094  0.002720\n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: alcoholism\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "1    1.0   1504   1135      369    0.022801       0.029532 -0.258673  0.001741\n",
      "0    0.0  60770  48644    12126    0.977199       0.970468  0.006912  0.000047\n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: handicap\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "0    0.0  61142  48828    12314    0.980896       0.985514 -0.004698  0.000022\n",
      "1    1.0   1132    951      181    0.019104       0.014486  0.276752  0.001278\n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: sms\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "0    1.0  21749  15825     5924    0.317905        0.47411 -0.399686  0.062433\n",
      "1    0.0  40525  33954     6571    0.682095        0.52589  0.260076  0.040625\n",
      "IV score: 0.10\n",
      "\n",
      "\n",
      "WoE and IV for column: appointment_weekday\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE        IV\n",
      "0    5.0  10008   7803     2205    0.156753       0.176471 -0.118484  0.002336\n",
      "1    1.0  12366   9790     2576    0.196669       0.206162 -0.047141  0.000448\n",
      "4    4.0   9483   7605     1878    0.152775       0.150300  0.016334  0.000040\n",
      "3    3.0  15469  12496     2973    0.251030       0.237935  0.053572  0.000701\n",
      "2    2.0  14948  12085     2863    0.242773       0.229132  0.057830  0.000789\n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: schedule_weekday\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "1    4.0  10028   7983     2045    0.160369       0.163665 -0.020348   \n",
      "0    2.0  15062  12021     3041    0.241487       0.243377 -0.007796   \n",
      "4    1.0  12987  10375     2612    0.208421       0.209044 -0.002982   \n",
      "2    5.0  10305   8237     2068    0.165471       0.165506 -0.000210   \n",
      "3    3.0  13892  11163     2729    0.224251       0.218407  0.026405   \n",
      "\n",
      "             IV  \n",
      "1  6.708045e-05  \n",
      "0  1.473413e-05  \n",
      "4  1.855853e-06  \n",
      "2  7.325936e-09  \n",
      "3  1.543054e-04  \n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: prior_noshows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adelweiss\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:853: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "7     6.0     13      2       11    0.000040       0.000880 -3.087013   \n",
      "12   10.0      4      1        3    0.000020       0.000240 -2.480877   \n",
      "2     2.0    516    152      364    0.003053       0.029132 -2.255538   \n",
      "4     3.0    162     49      113    0.000984       0.009044 -2.217832   \n",
      "1     1.0   2412    736     1676    0.014785       0.134134 -2.205200   \n",
      "6     7.0      9      3        6    0.000060       0.000480 -2.075412   \n",
      "11    8.0      3      1        2    0.000020       0.000160 -2.075412   \n",
      "3     5.0     33     12       21    0.000241       0.001681 -1.941880   \n",
      "5     4.0     58     24       34    0.000482       0.002721 -1.730571   \n",
      "8    12.0      1      0        1    0.000000       0.000080  0.000000   \n",
      "14   13.0      1      0        1    0.000000       0.000080  0.000000   \n",
      "13   17.0      1      0        1    0.000000       0.000080  0.000000   \n",
      "16   11.0      1      0        1    0.000000       0.000080  0.000000   \n",
      "9     9.0      4      0        4    0.000000       0.000320  0.000000   \n",
      "15   15.0      1      0        1    0.000000       0.000080  0.000000   \n",
      "10   14.0      1      0        1    0.000000       0.000080  0.000000   \n",
      "0     0.0  59054  48799    10255    0.980313       0.820728  0.177680   \n",
      "\n",
      "          IV  \n",
      "7   0.002594  \n",
      "12  0.000546  \n",
      "2   0.058820  \n",
      "4   0.017874  \n",
      "1   0.263187  \n",
      "6   0.000872  \n",
      "11  0.000291  \n",
      "3   0.002796  \n",
      "5   0.003875  \n",
      "8  -0.000000  \n",
      "14 -0.000000  \n",
      "13 -0.000000  \n",
      "16 -0.000000  \n",
      "9  -0.000000  \n",
      "15 -0.000000  \n",
      "10 -0.000000  \n",
      "0   0.028355  \n",
      "IV score: 0.38\n",
      "\n",
      "\n",
      "WoE and IV for column: total_conditions\n",
      "   Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "0    0.0  47785  37765    10020    0.758653       0.801921 -0.055465   \n",
      "4    4.0      5      4        1    0.000080       0.000080  0.004030   \n",
      "1    1.0  10037   8302     1735    0.166777       0.138856  0.183224   \n",
      "2    2.0   4117   3429      688    0.068884       0.055062  0.223970   \n",
      "3    3.0    330    279       51    0.005605       0.004082  0.317122   \n",
      "\n",
      "             IV  \n",
      "0  2.399833e-03  \n",
      "4  1.302231e-09  \n",
      "1  5.115921e-03  \n",
      "2  3.095819e-03  \n",
      "3  4.830206e-04  \n",
      "IV score: 0.01\n",
      "\n",
      "\n",
      "WoE and IV for column: age_bins\n",
      "           Value   All  Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "1   (20.0, 29.0]  6804  5041     1763    0.101268       0.141096 -0.331677   \n",
      "5   (12.0, 20.0]  6134  4577     1557    0.091946       0.124610 -0.303982   \n",
      "4   (29.0, 36.0]  5656  4345     1311    0.087286       0.104922 -0.184029   \n",
      "7    (4.0, 12.0]  6282  4885     1397    0.098134       0.111805 -0.130422   \n",
      "0   (36.0, 44.0]  6167  4817     1350    0.096768       0.108043 -0.110218   \n",
      "2   (44.0, 52.0]  6654  5415     1239    0.108781       0.099160  0.092604   \n",
      "9  (-0.001, 4.0]  6378  5229     1149    0.105044       0.091957  0.133063   \n",
      "3   (52.0, 59.0]  6017  5004     1013    0.100524       0.081072  0.215057   \n",
      "8   (59.0, 68.0]  6222  5343      879    0.107334       0.070348  0.422493   \n",
      "6  (68.0, 115.0]  5960  5123      837    0.102915       0.066987  0.429407   \n",
      "\n",
      "         IV  \n",
      "1  0.013210  \n",
      "5  0.009929  \n",
      "4  0.003246  \n",
      "7  0.001783  \n",
      "0  0.001243  \n",
      "2  0.000891  \n",
      "9  0.001741  \n",
      "3  0.004183  \n",
      "8  0.015626  \n",
      "6  0.015428  \n",
      "IV score: 0.07\n",
      "\n",
      "\n",
      "WoE and IV for column: schedule_hour_bins\n",
      "          Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "1  (12.0, 21.0]  20035  15476     4559    0.310894       0.364866 -0.160078   \n",
      "0   (8.0, 12.0]  21125  16579     4546    0.333052       0.363826 -0.088376   \n",
      "2  (5.999, 8.0]  21114  17724     3390    0.356054       0.271309  0.271825   \n",
      "\n",
      "         IV  \n",
      "1  0.008640  \n",
      "0  0.002720  \n",
      "2  0.023036  \n",
      "IV score: 0.03\n",
      "\n",
      "\n",
      "WoE and IV for column: schedule_day_bins\n",
      "          Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "1  (13.0, 22.0]  14393  11148     3245    0.223950       0.259704 -0.148120   \n",
      "0  (22.0, 31.0]  15477  11991     3486    0.240885       0.278992 -0.146863   \n",
      "2   (6.0, 13.0]  13914  11366     2548    0.228329       0.203922  0.113053   \n",
      "3  (0.999, 6.0]  18490  15274     3216    0.306836       0.257383  0.175749   \n",
      "\n",
      "         IV  \n",
      "1  0.005296  \n",
      "0  0.005597  \n",
      "2  0.002759  \n",
      "3  0.008691  \n",
      "IV score: 0.02\n",
      "\n",
      "\n",
      "WoE and IV for column: appointment_day_bins\n",
      "          Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "3   (9.0, 19.0]  17369  13706     3663    0.275337       0.293157 -0.062713   \n",
      "0  (19.0, 31.0]  13683  10919     2764    0.219350       0.221208 -0.008439   \n",
      "1  (0.999, 5.0]  15955  12809     3146    0.257317       0.251781  0.021752   \n",
      "2    (5.0, 9.0]  15267  12345     2922    0.247996       0.233854  0.058718   \n",
      "\n",
      "         IV  \n",
      "3  0.001118  \n",
      "0  0.000016  \n",
      "1  0.000120  \n",
      "2  0.000830  \n",
      "IV score: 0.00\n",
      "\n",
      "\n",
      "WoE and IV for column: day_difference_bins\n",
      "           Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "0  (21.0, 179.0]  12298   8369     3929    0.168123       0.314446 -0.626115   \n",
      "2    (7.0, 21.0]  12090   8342     3748    0.167581       0.299960 -0.582184   \n",
      "3     (2.0, 7.0]  10526   7915     2611    0.159003       0.208964 -0.273238   \n",
      "1  (-0.001, 2.0]  27360  25153     2207    0.505293       0.176631  1.051078   \n",
      "\n",
      "         IV  \n",
      "0  0.091615  \n",
      "2  0.077069  \n",
      "3  0.013651  \n",
      "1  0.345450  \n",
      "IV score: 0.53\n",
      "\n",
      "\n",
      "WoE and IV for column: prior_appointments_bins\n",
      "           Value    All   Show  No_show  Distr_show  Distr_no_show       WoE  \\\n",
      "1    (1.0, 87.0]  10473   8057     2416    0.161855       0.193357 -0.177837   \n",
      "0  (-0.001, 1.0]  51801  41722    10079    0.838145       0.806643  0.038310   \n",
      "\n",
      "         IV  \n",
      "1  0.005602  \n",
      "0  0.001207  \n",
      "IV score: 0.01\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df_eda.columns:\n",
    "    if col == 'no_show': continue\n",
    "    else:\n",
    "        print('WoE and IV for column: {}'.format(col))\n",
    "        df_woe_iv, iv = calculate_woe_iv(df_eda, col, 'no_show')\n",
    "        print(df_woe_iv)\n",
    "        print('IV score: {:.2f}'.format(iv))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['hypertension','sms','prior_noshows','age', 'schedule_hour', \n",
    "         'schedule_day', 'day_difference', 'no_show']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df, hue='no_show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>sms</th>\n",
       "      <th>prior_noshows</th>\n",
       "      <th>age</th>\n",
       "      <th>schedule_hour</th>\n",
       "      <th>schedule_day</th>\n",
       "      <th>day_difference</th>\n",
       "      <th>no_show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hypertension</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009240</td>\n",
       "      <td>-0.015931</td>\n",
       "      <td>0.513201</td>\n",
       "      <td>-0.037955</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>-0.049180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sms</td>\n",
       "      <td>-0.009240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>0.063555</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.408027</td>\n",
       "      <td>0.131221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>prior_noshows</td>\n",
       "      <td>-0.015931</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>0.228932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>age</td>\n",
       "      <td>0.513201</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>-0.009541</td>\n",
       "      <td>0.043650</td>\n",
       "      <td>-0.068350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>schedule_hour</td>\n",
       "      <td>-0.037955</td>\n",
       "      <td>0.063555</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>0.066827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>schedule_day</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>-0.009541</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.053577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>day_difference</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>0.408027</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>0.043650</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>no_show</td>\n",
       "      <td>-0.049180</td>\n",
       "      <td>0.131221</td>\n",
       "      <td>0.228932</td>\n",
       "      <td>-0.068350</td>\n",
       "      <td>0.066827</td>\n",
       "      <td>0.053577</td>\n",
       "      <td>0.188333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                hypertension       sms  prior_noshows       age  \\\n",
       "hypertension        1.000000 -0.009240      -0.015931  0.513201   \n",
       "sms                -0.009240  1.000000       0.034937  0.020381   \n",
       "prior_noshows      -0.015931  0.034937       1.000000 -0.020314   \n",
       "age                 0.513201  0.020381      -0.020314  1.000000   \n",
       "schedule_hour      -0.037955  0.063555       0.032333  0.008413   \n",
       "schedule_day       -0.001580  0.141176       0.003857 -0.009541   \n",
       "day_difference     -0.016745  0.408027       0.020503  0.043650   \n",
       "no_show            -0.049180  0.131221       0.228932 -0.068350   \n",
       "\n",
       "                schedule_hour  schedule_day  day_difference   no_show  \n",
       "hypertension        -0.037955     -0.001580       -0.016745 -0.049180  \n",
       "sms                  0.063555      0.141176        0.408027  0.131221  \n",
       "prior_noshows        0.032333      0.003857        0.020503  0.228932  \n",
       "age                  0.008413     -0.009541        0.043650 -0.068350  \n",
       "schedule_hour        1.000000      0.016815        0.091563  0.066827  \n",
       "schedule_day         0.016815      1.000000        0.044597  0.053577  \n",
       "day_difference       0.091563      0.044597        1.000000  0.188333  \n",
       "no_show              0.066827      0.053577        0.188333  1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### tried binning the age to see if model performance improved, but looks like its better to leave it \n",
    "# bins = range(0,105,5)\n",
    "# age_labels = range(1,21)\n",
    "\n",
    "# df['age_categories'] = pd.cut(df['age'], bins, labels=age_labels, include_lowest = True) \n",
    "# df.loc[df.age>99, 'age_categories'] = 19 ### add all of those 100 and above to the last category \n",
    "# df['age'] = df['age_categories']\n",
    "# df.drop(columns=['age_categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(['no_show'],axis=1), df['no_show'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train) \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_accuracy = []\n",
    "log_recall = []\n",
    "log_precision = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val] \n",
    "    \n",
    "    log_reg = LogisticRegression(solver= 'liblinear')\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    log_reg.fit(scaled_X_trainfold, y_trainfold)\n",
    "    #y_predict = (log_reg.predict_proba(scaled_X_valfold)[:,1] > 0.22)\n",
    "    y_predict = log_reg.predict(scaled_X_valfold)\n",
    "    log_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    log_recall.append(recall_score(y_valfold, y_predict))\n",
    "    log_precision.append(precision_score(y_valfold, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8158131433151314\n",
      "0.133765111575112\n",
      "0.6955719204501621\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(log_accuracy))\n",
    "print(np.mean(log_recall))\n",
    "print(np.mean(log_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy = []\n",
    "knn_recall = []\n",
    "knn_precision = []\n",
    "knn_roc = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val]\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=29) ###seting optimum to an odd number \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    knn.fit(scaled_X_trainfold, y_trainfold)\n",
    "    y_predict = knn.predict(scaled_X_valfold)\n",
    "    \n",
    "    knn_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    knn_recall.append(recall_score(y_valfold, y_predict))\n",
    "    knn_precision.append(precision_score(y_valfold, y_predict))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8190247270984538\n",
      "0.18928845564958027\n",
      "0.6589771876195176\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(knn_accuracy))\n",
    "print(np.mean(knn_recall))\n",
    "print(np.mean(knn_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   46.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 28}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "k_range = list(range(1, 31))\n",
    "param_dist = dict(n_neighbors=k_range)\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=3, scoring='accuracy', verbose=2, random_state=42, n_jobs = -1)\n",
    "rand.fit(scaled_X_train, y_train)\n",
    "\n",
    "rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for randomizedsearch CV for tuning hyperparameters\n",
    "\n",
    "reference: https://medium.com/@aneesha/svm-parameter-tuning-in-scikit-learn-using-gridsearchcv-2413c02125a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "svm_random_grid = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    " 'gamma': [0.001, 0.01, 0.1, 1]} #'class_weight':[{0:0.62550473,1:2.49195678}]}\n",
    "\n",
    "svm_random = RandomizedSearchCV(estimator = svm.SVC(kernel ='rbf'), param_distributions = svm_random_grid,\n",
    "                                n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "svm_random.fit(scaled_X_train, y_train)\n",
    "svm_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimised SVM Radial \n",
    "\n",
    "Accuracy: 0.821654277792908 <p>\n",
    "Recall: 0.1535268532949164 <p> \n",
    "Precision: 0.7578844329944994 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmrbf_accuracy = []\n",
    "svmrbf_recall = []\n",
    "svmrbf_precision = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    svm_rbf = svm.SVC(kernel=\"rbf\", gamma=0.1, C=10)\n",
    "    svm_rbf.fit(scaled_X_trainfold, y_trainfold)\n",
    "    \n",
    "    y_predict = svm_rbf.predict(scaled_X_valfold)\n",
    "    \n",
    "    svmrbf_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    svmrbf_recall.append(recall_score(y_valfold, y_predict))\n",
    "    svmrbf_precision.append(precision_score(y_valfold, y_predict))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(svmrbf_accuracy))\n",
    "print(np.mean(svmrbf_recall))\n",
    "print(np.mean(svmrbf_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimised SVM Radial with class weight \n",
    "\n",
    "Accuracy: 0.7988117838491379 <p>\n",
    "Recall: 0.16890676075436756 <p> \n",
    "Precision: 0.5501785181618126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0,1]\n",
    "cw = compute_class_weight('balanced', classes, df.no_show)\n",
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmrbf_accuracy = []\n",
    "svmrbf_recall = []\n",
    "svmrbf_precision = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    svm_rbf = svm.SVC(kernel=\"rbf\", gamma=0.01, C=0.001, class_weight = {0:0.62550473,1:2.49195678}) \n",
    "    svm_rbf.fit(scaled_X_trainfold, y_trainfold)\n",
    "    \n",
    "    y_predict = svm_rbf.predict(scaled_X_valfold)\n",
    "    \n",
    "    svmrbf_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    svmrbf_recall.append(recall_score(y_valfold, y_predict))\n",
    "    svmrbf_precision.append(precision_score(y_valfold, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7574628977477605\n",
      "0.19504901525778046\n",
      "0.6394577497400336\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(svmrbf_accuracy))\n",
    "print(np.mean(svmrbf_recall))\n",
    "print(np.mean(svmrbf_precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_accuracy = []\n",
    "nb_recall = []\n",
    "nb_precision = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    nb = GaussianNB()\n",
    "    nb.fit(scaled_X_trainfold, y_trainfold)\n",
    "\n",
    "    y_predict = nb.predict(scaled_X_valfold)\n",
    "    \n",
    "    nb_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    nb_recall.append(recall_score(y_valfold, y_predict))\n",
    "    nb_precision.append(precision_score(y_valfold, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814086945060836\n",
      "0.1997979921113334\n",
      "0.6002664846978236\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(nb_accuracy))\n",
    "print(np.mean(nb_recall))\n",
    "print(np.mean(nb_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for randomizedsearch CV for tuning hyperparameters\n",
    "\n",
    "reference: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100,\n",
       " 'class_weight': {0: 0.62550473, 1: 2.49195678}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "random_grid = {'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "              'class_weight':[{0:0.62550473,1:2.49195678}]}\n",
    " \n",
    "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier() , scoring = 'accuracy', param_distributions = random_grid\n",
    "                               , n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(scaled_X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "                       class_weight={0: 0.62550473, 1: 2.49195678},\n",
       "                       criterion='gini', max_depth=100, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=1800, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimised Randomforest \n",
    "\n",
    "Accuracy: 0.8249662752586012 <p>\n",
    "Recall: 0.16894635563896582 <p> \n",
    "Precision: 0.7794004157029264 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = []\n",
    "rf_recall = []\n",
    "rf_precision = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 400, min_samples_split = 2, min_samples_leaf = 2, \n",
    "                                max_features = 'sqrt', max_depth = 10, n_jobs = -1)\n",
    "    rf.fit(scaled_X_trainfold, y_trainfold)\n",
    "\n",
    "    y_predict = rf.predict(scaled_X_valfold)\n",
    "    \n",
    "    rf_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    rf_recall.append(recall_score(y_valfold, y_predict))\n",
    "    rf_precision.append(precision_score(y_valfold, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(rf_accuracy))\n",
    "print(np.mean(rf_recall))\n",
    "print(np.mean(rf_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomforest optimised for class weight\n",
    "\n",
    "Accuracy: 0.7878117460940285 <p>\n",
    "Recall: 0.34327949214184883 <p> \n",
    "Precision: 0.45657089201211465 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = []\n",
    "rf_recall = []\n",
    "rf_precision = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 400, min_samples_split = 2, min_samples_leaf = 2, \n",
    "                              max_features = 'sqrt', max_depth = 10, class_weight= {0:0.62550473,1:2.49195678}, n_jobs = -1)\n",
    "   \n",
    "    rf.fit(scaled_X_trainfold, y_trainfold)\n",
    "\n",
    "    y_predict = rf.predict(scaled_X_valfold)\n",
    "    \n",
    "    rf_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    rf_recall.append(recall_score(y_valfold, y_predict))\n",
    "    rf_precision.append(precision_score(y_valfold, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7871493393480407\n",
      "0.34342029105110955\n",
      "0.45457495136780474\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(rf_accuracy))\n",
    "print(np.mean(rf_recall))\n",
    "print(np.mean(rf_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting RF to entire training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### fit RF to entire training set \n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 400, min_samples_split = 2, min_samples_leaf = 2, \n",
    "                                max_features = 'sqrt', max_depth = 10, n_jobs = -1)\n",
    "rf.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = ( rf.predict_proba(scaled_X_test)[:, 1] >= 0.38).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score =  0.8239222751255315\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, rf.predict_proba(scaled_X_train)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_train, rf.predict_proba(scaled_X_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, rf.predict_proba(scaled_X_train)[:,1] )\n",
    "\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold')\n",
    "plt.title('Precision and Recall Curves');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.97      0.89      9882\n",
      "         1.0       0.67      0.21      0.32      2573\n",
      "\n",
      "    accuracy                           0.82     12455\n",
      "   macro avg       0.75      0.59      0.60     12455\n",
      "weighted avg       0.79      0.82      0.77     12455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf = svm.SVC(kernel=\"rbf\", gamma=0.1, C=10)\n",
    "svm_rbf.fit(scaled_X_train, y_train, probability = True) ### to try this tmr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-3a39ee1d666d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0msvm_rbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.38\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \"\"\"\n\u001b[1;32m--> 616\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    584\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    585\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "y_predict = ( svm_rbf.predict_proba(scaled_X_test)[:, 1] >= 0.38).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, svm_rbf.predict_proba(scaled_X_train)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_train, svm_rbf.predict_proba(scaled_X_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, svm_rbf.predict_proba(scaled_X_train)[:,1] )\n",
    "\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold')\n",
    "plt.title('Precision and Recall Curves');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_valfold, log_reg.predict_proba(scaled_X_valfold)[:,1] )\n",
    "\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold')\n",
    "plt.title('Precision and Recall Curves');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_valfold, log_reg.predict_proba(scaled_X_valfold)[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_valfold, log_reg.predict_proba(scaled_X_valfold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### don't think we will get very good results even if we tune this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### even if knn optimised, recall seems bad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmpoly_accuracy = []\n",
    "svmpoly_recall = []\n",
    "svmpoly_precision = []\n",
    "\n",
    "for train, val in kf.split(X_train, y_train):\n",
    "    X_trainfold, y_trainfold = X_train[train], y_train[train]\n",
    "    X_valfold, y_valfold = X_train[val], y_train[val]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_X_trainfold = scaler.fit_transform(X_trainfold)\n",
    "    scaled_X_valfold = scaler.transform(X_valfold)\n",
    "    \n",
    "    svm_poly = svm.SVC(kernel=\"poly\")\n",
    "    svm_poly.fit(scaled_X_trainfold, y_trainfold)\n",
    "    \n",
    "    y_predict = svm_poly.predict(scaled_X_valfold)\n",
    "    \n",
    "    svmrbf_accuracy.append(accuracy_score(y_valfold, y_predict))\n",
    "    svmrbf_recall.append(recall_score(y_valfold, y_predict))\n",
    "    svmrbf_precision.append(precision_score(y_valfold, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
